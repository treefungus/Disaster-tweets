{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-01-05T20:07:51.719825Z","iopub.execute_input":"2025-01-05T20:07:51.720167Z","iopub.status.idle":"2025-01-05T20:07:51.728679Z","shell.execute_reply.started":"2025-01-05T20:07:51.720140Z","shell.execute_reply":"2025-01-05T20:07:51.727484Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","output_type":"stream"}],"execution_count":78},{"cell_type":"markdown","source":"## Predicting Disaster Tweets\n\nThis is my next attempt to predict which tweets regard an actual disaster and which do not in the [competition](https://www.kaggle.com/competitions/nlp-getting-started).\n\nThis time applying modest neural model.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import TextVectorization\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\ndata = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:07:51.730365Z","iopub.execute_input":"2025-01-05T20:07:51.730739Z","iopub.status.idle":"2025-01-05T20:07:51.782792Z","shell.execute_reply.started":"2025-01-05T20:07:51.730703Z","shell.execute_reply":"2025-01-05T20:07:51.781648Z"}},"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":79},{"cell_type":"code","source":"data.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:07:51.785065Z","iopub.execute_input":"2025-01-05T20:07:51.785385Z","iopub.status.idle":"2025-01-05T20:07:51.793053Z","shell.execute_reply.started":"2025-01-05T20:07:51.785357Z","shell.execute_reply":"2025-01-05T20:07:51.792134Z"}},"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"id             0\nkeyword       61\nlocation    2533\ntext           0\ntarget         0\ndtype: int64"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:07:51.794472Z","iopub.execute_input":"2025-01-05T20:07:51.794777Z","iopub.status.idle":"2025-01-05T20:07:51.807007Z","shell.execute_reply.started":"2025-01-05T20:07:51.794753Z","shell.execute_reply":"2025-01-05T20:07:51.806181Z"}},"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"(7613, 5)"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"df = data[[\"text\", \"target\"]]\ndf_test = test_data[\"text\"]\n\ndf.info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:07:51.808101Z","iopub.execute_input":"2025-01-05T20:07:51.808424Z","iopub.status.idle":"2025-01-05T20:07:51.826811Z","shell.execute_reply.started":"2025-01-05T20:07:51.808394Z","shell.execute_reply":"2025-01-05T20:07:51.825714Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"<bound method DataFrame.info of                                                    text  target\n0     Our Deeds are the Reason of this #earthquake M...       1\n1                Forest fire near La Ronge Sask. Canada       1\n2     All residents asked to 'shelter in place' are ...       1\n3     13,000 people receive #wildfires evacuation or...       1\n4     Just got sent this photo from Ruby #Alaska as ...       1\n...                                                 ...     ...\n7608  Two giant cranes holding a bridge collapse int...       1\n7609  @aria_ahrary @TheTawniest The out of control w...       1\n7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n7611  Police investigating after an e-bike collided ...       1\n7612  The Latest: More Homes Razed by Northern Calif...       1\n\n[7613 rows x 2 columns]>"},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"#text_data = np.array(df[\"text\"])\n\n#print(text_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:07:51.827821Z","iopub.execute_input":"2025-01-05T20:07:51.828345Z","iopub.status.idle":"2025-01-05T20:07:51.838106Z","shell.execute_reply.started":"2025-01-05T20:07:51.828283Z","shell.execute_reply":"2025-01-05T20:07:51.837326Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"#df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:07:51.839016Z","iopub.execute_input":"2025-01-05T20:07:51.839371Z","iopub.status.idle":"2025-01-05T20:07:51.850712Z","shell.execute_reply.started":"2025-01-05T20:07:51.839345Z","shell.execute_reply":"2025-01-05T20:07:51.849654Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"#vectorizer = TextVectorization(max_tokens=10000, output_mode='int', output_sequence_length=10)\n\n#vectorizer.adapt(text_data)\n\n#vectorized_text = vectorizer(text_data).numpy()\n\n#df[\"text\"] = list(vectorized_text)\n#df.head()\n\n#\nX = df[\"text\"]\ny = df[\"target\"]\n\n# Splitting the data to training, validation and testing sets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y)\nX_test = df_test\n\n# Adapting the vectorizer on training data only\ntext_data_train = np.array(X_train)\n\nvectorizer = TextVectorization(max_tokens=10000, output_mode='int', output_sequence_length=10)\nvectorizer.adapt(text_data_train)\n\n# Creating vectors for training, validation and testing text strings\ndef vectorize(data, vectorizer):\n    return vectorizer(np.array(data)).numpy()\n    \nX_train_vectorized = vectorizer(np.array(X_train)).numpy()\nX_valid_vectorized = vectorizer(np.array(X_valid)).numpy()\nX_test_vectorized = vectorizer(np.array(X_test)).numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:07:51.853409Z","iopub.execute_input":"2025-01-05T20:07:51.853694Z","iopub.status.idle":"2025-01-05T20:07:52.018717Z","shell.execute_reply.started":"2025-01-05T20:07:51.853668Z","shell.execute_reply":"2025-01-05T20:07:52.017862Z"}},"outputs":[],"execution_count":85},{"cell_type":"markdown","source":"## Apply neural model\n\nNow we have our strings vectorized, let's build basic neural model and let it chew.","metadata":{}},{"cell_type":"code","source":"#input_shape = [df.drop('target', axis=1).columns.nunique()]\n#print(input_shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:07:52.019933Z","iopub.execute_input":"2025-01-05T20:07:52.020287Z","iopub.status.idle":"2025-01-05T20:07:52.024075Z","shell.execute_reply.started":"2025-01-05T20:07:52.020251Z","shell.execute_reply":"2025-01-05T20:07:52.023141Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(\n    patience=5,\n    min_delta=0.0001,\n    restore_best_weights=True,\n)\n\nmodel = keras.Sequential([\n    layers.Embedding(input_dim=10000, output_dim=31, input_shape=[1]),\n    layers.GlobalAveragePooling1D(),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(units=64, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(units=64, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(units=64, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(units=1, activation=\"sigmoid\")\n])\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"binary_crossentropy\",\n    metrics=[\"binary_accuracy\"]\n)\n\n#X = np.array(df[\"text\"].tolist())\n#y = df[\"target\"]\n\n#X_train, X_test, y_train, y_test = train_test_split(X, y)\nmodel.fit(\n    X_train_vectorized, y_train,\n    validation_data=(X_valid_vectorized, y_valid),\n    batch_size=256,\n    epochs=30,\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:07:52.025048Z","iopub.execute_input":"2025-01-05T20:07:52.025361Z","iopub.status.idle":"2025-01-05T20:07:58.109564Z","shell.execute_reply.started":"2025-01-05T20:07:52.025329Z","shell.execute_reply":"2025-01-05T20:07:58.108535Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - binary_accuracy: 0.5358 - loss: 0.8512 - val_binary_accuracy: 0.5714 - val_loss: 0.6852\nEpoch 2/30\n\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.5981 - loss: 0.7187 - val_binary_accuracy: 0.5714 - val_loss: 0.6817\nEpoch 3/30\n\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.6678 - loss: 0.6400 - val_binary_accuracy: 0.5714 - val_loss: 0.6776\nEpoch 4/30\n\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7151 - loss: 0.5638 - val_binary_accuracy: 0.5714 - val_loss: 0.6715\nEpoch 5/30\n\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.7878 - loss: 0.4837 - val_binary_accuracy: 0.5720 - val_loss: 0.6617\nEpoch 6/30\n\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8156 - loss: 0.4264 - val_binary_accuracy: 0.6991 - val_loss: 0.6518\nEpoch 7/30\n\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8447 - loss: 0.3708 - val_binary_accuracy: 0.6917 - val_loss: 0.6469\nEpoch 8/30\n\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8732 - loss: 0.3187 - val_binary_accuracy: 0.4842 - val_loss: 0.6653\nEpoch 9/30\n\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.8927 - loss: 0.2873 - val_binary_accuracy: 0.4905 - val_loss: 0.6644\nEpoch 10/30\n\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9015 - loss: 0.2416 - val_binary_accuracy: 0.4764 - val_loss: 0.6892\nEpoch 11/30\n\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 0.9158 - loss: 0.2200 - val_binary_accuracy: 0.4695 - val_loss: 0.7361\nEpoch 12/30\n\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9312 - loss: 0.1979 - val_binary_accuracy: 0.4711 - val_loss: 0.7898\n","output_type":"stream"},{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7c34e9147400>"},"metadata":{}}],"execution_count":87},{"cell_type":"code","source":"#df_test = test_data.copy()\n#text_data_test = np.array(df_test[\"text\"])\n#vectorizer = TextVectorization(max_tokens=10000, output_mode='int')\n#vectorizer.adapt(text_data_test)\n\n#vectorized_text_test = vectorizer(text_data_test).numpy()\n#print(vectorized_text_test.shape)\n\n#df_test[\"text\"] = vectorized_text_test\n\n#df_test[\"text\"].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:07:58.110578Z","iopub.execute_input":"2025-01-05T20:07:58.110871Z","iopub.status.idle":"2025-01-05T20:07:58.114908Z","shell.execute_reply.started":"2025-01-05T20:07:58.110837Z","shell.execute_reply":"2025-01-05T20:07:58.113810Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"#X_tested = df_test[\"text\"]\n#print(len(X_tested))\n\nmy_predictions = model.predict(X_test_vectorized).flatten()\nbinary_predictions = (my_predictions > 0.5).astype(int)\n\nsubmission = pd.DataFrame({'id': test_data['id'],\n                           'target': binary_predictions})\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:08:49.590486Z","iopub.execute_input":"2025-01-05T20:08:49.590907Z","iopub.status.idle":"2025-01-05T20:08:49.818235Z","shell.execute_reply.started":"2025-01-05T20:08:49.590872Z","shell.execute_reply":"2025-01-05T20:08:49.817209Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n[1 0 1 ... 1 1 1]\n","output_type":"stream"}],"execution_count":90}]}